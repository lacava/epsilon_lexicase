%\documentclass[preprint]{article}
%\renewcommand{\rmdefault}{ppl}
%\usepackage[margin=1.25in]{geometry}
\documentclass[twoside]{article}
\usepackage{ecj,palatino,epsfig,latexsym,natbib}

\usepackage{graphicx}
\usepackage{placeins}

\usepackage{amsmath}
\usepackage{wasysym}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\usepackage{booktabs}
\usepackage{tabularx}
%\usepackage[font=small]{caption}
%\usepackage[strings]{underscore}
%\usepackage{subfigure}
\usepackage{color}
\usepackage{floatflt}
\usepackage[table]{xcolor}
\definecolor{Gray}{gray}{0.9}
%\usepackage[boxed]{algorithm2e}
%\usepackage{lmacro}
%\topmargin=-0.5in\usepackage[table]{xcolor}
\definecolor{White}{rgb}{1,1,1}
\definecolor{Gray}{gray}{0.9}
\definecolor{LightCyan}{rgb}{0.88,1,1}
\usepackage{soul}
\usepackage{sidecap}
\graphicspath{{./Figures/}}
%\usepackage[margin=1.2in]{geometry}
\usepackage{hyperref}
\hypersetup{colorlinks=true,
citecolor=black,
linkcolor=black,
urlcolor=black}

\usepackage{algorithm,algorithmicx}
\usepackage[noend]{algpseudocode}
\newcommand*\DNA{\textsc{dna}}

\newcommand*\Let[2]{\State #1 $\gets$ #2}
\algrenewcommand\algorithmicrequire{\textbf{Precondition:}}
\algrenewcommand\algorithmicensure{\textbf{Postcondition:}}
%\usepackage{fontspec}
%\setmainfont{Hoefler Text}
%\newcommand*\DNA{\textsc{dna}}
%
%\newcommand*\Let[2]{\State #1 $\gets$ #2}
%\algrenewcommand\alglinenumber[1]{
%    {\sf\footnotesize\addfontfeatures{Colour=888888,Numbers=Monospaced}#1}}
%\algrenewcommand\algorithmicrequire{\textbf{Precondition:}}
%\algrenewcommand\algorithmicensure{\textbf{Postcondition:}}

%\author{William La Cava, Lee Spector, Jason Moore}

% theorems
\newtheorem{dom}{Definition}[section]
\newtheorem{pareto}{Definition}[section]
\newtheorem{boundary}{Definition}[section]

\newtheorem{lex}{Theorem}[section]
\newtheorem{defn}[lex]{Definition}
%% ep lex
%\newtheorem{ep-dom}{Definition}[section]
%\newtheorem{ep-pareto}{Definition}[section]
%\newtheorem{ep-boundary}{Definition}[section]
%\newtheorem{eplex}{Theorem}[section]

\begin{document}

%\numberofauthors{3}
%
%\alignauthor
%William La Cava\titlenote{corresponding author} \\
%       \affaddr{Department of Mechanical and Industrial Engineering}\\
%       \affaddr{University of Massachusetts}\\
%       \affaddr{Amherst, MA 01003}\\
%       \email{wlacava@umass.edu}
%%%\alignauthor
%%%Thomas Helmuth\\
%%%       \affaddr{Department of Computer Science}\\
%%%       \affaddr{University of Massachusetts}\\
%%%       \affaddr{Amherst, MA 01003}\\
%%%       \email{thelmuth@umass.edu}
%\alignauthor
%Lee Spector\\
%       \affaddr{School of Cognitive Science}\\
%       \affaddr{Hampshire College}\\
%       \affaddr{Amherst, MA 01002}\\
%       \email{lspector@hampshire.edu}
%\and
%\alignauthor
%Kourosh Danai\\
%       \affaddr{Department of Mechanical and Industrial Engineering}\\
%       \affaddr{University of Massachusetts}\\
%       \affaddr{Amherst, MA 01003}\\
%       \email{danai@engin.umass.edu}
%}

%\maketitle
%\ead{danai@ecs.umass.edu}
%\cortext[cor1]{Corresponding author}
%\address[mie]{D, , Amherst, MA 01003}
%\address[hc]{School of Cognitive Science, Hampshire College, Amherst MA 01002}
%
\ecjHeader{x}{x}{xxx-xxx}{201X}{$\epsilon$-Lexicase selection}{W. La Cava}
\title{{\bf \huge $\epsilon$}-Lexicase selection: a probabilistic and multi-objective analysis of lexicase selection in continuous domains}  

\author{\name{\bf William La Cava} \hfill \addr{lacava@upenn.edu}\\ 
        \addr{Institute for Bioinformatics, University of Pennsylvania, 
        Philadelphia, PA, 19104, USA}
\AND
       \name{\bf Thomas Helmuth} \hfill \addr{helmutht@wlu.edu}\\
        \addr{Department of Computer Science, Washington and Lee University, 
        Lexington, VA, USA}        
\AND
       \name{\bf Lee Spector} \hfill \addr{lspector@hampshire.edu}\\
        \addr{School of Cognitive Science, Hampshire College, 
        Amherst, MA, 01002, USA}
\AND
	   \name{\bf Jason H. Moore} \hfill \addr{jhmoore@upenn.edu}\\
	   \addr{Institute for Bioinformatics, University of Pennsylvania, 
        Philadelphia, PA, 19104, USA}
}

\maketitle
\maketitle
\begin{abstract}
Lexicase selection is a parent selection method that considers training cases individually, rather than in aggregate, when performing parent selection. Whereas previous work has demonstrated the ability of lexicase selection to solve difficult problems, the central goal of this paper is to develop the theoretical underpinnings that explain its performance. To this end, we derive an analytical formula that gives the expected probabilities of selection under lexicase selection, given a population and its behavior. In addition, we expand upon the relation of lexicase selection to many-objective optimization methods to describe the behavior of lexicase, which is to select individuals on the boundaries of Pareto fronts in high-dimensional space. We show analytically why lexicase selection performs more poorly for certain sizes of population and training cases, and show why it has been shown to perform more poorly in continuous error spaces. To address this last concern, we introduce $\epsilon$-lexicase selection, which modifies the pass condition in lexicase selection to allow near-elite individuals to pass cases, thereby improving selection performance with continuous errors. We show that $\epsilon$-lexicase outperforms several diversity-maintenance strategies on a number of real-world and synthetic regression problems.
\end{abstract}


\section{Introduction}
  
Evolutionary computation (EC) traditionally assigns scalar fitness values to candidate solutions to determine how to guide search. In the case of genetic programming (GP), this fitness value summarizes how closely, on average, the behavior of the candidate programs match the desired behavior. Take for example the task of symbolic regression, in which we attempt to find a model using a set of training examples, i.e. cases. A typical fitness measure is the mean squared error (MSE), which averages the squared differences between the model's outputs, $\hat{y}$, and the target outputs, $y$. The effect of this averaging is to reduce a rich set of information comparing the model's output and the desired output to a single scalar value. As noted by \cite{krawiec_behavioral_2016}, the relationship of $\hat{y}$ to $y$ can only be represented crudely by this fitness value. The fitness score thereby restricts the information conveyed to the search process about candidate programs relative to the description of their behavior available in the raw comparisons of the output to the target, information which could help guide the search~\citep{chrisgptp2015behavioral, krawiec_automatic_2015}. This observation has led to increased interest in the development of methods that can leverage the program outputs directly to drive search more effectively~\citep{vanneschi_survey_2014}.

In addition to reducing information, averaging test performance assumes all tests are equally informative, leading to the potential loss of individuals who perform poorly {\it on average} even if they are the best on a training case that is difficult for most of the population to solve. This is particularly relevant for problems that require different modes of behavior to produce an adequate solution to the problem~\citep{spector_assessment_2012}. The underlying assumption of traditional selection methods is that selection pressure should be applied evenly with respect to training cases. In practice, cases that comprise the problem are unlikely to be uniformly difficult. As a result, the search is likely to benefit if it can take into account the difficulty of specific cases by recognizing individuals that perform well on harder parts of the problem. Underlying this last point is the assumption that GP solves problems by identifying, propagating and recombining partial solutions (i.e. building blocks) to the task at hand~\citep{poli_schema_1998}. As a result, a program that performs well on unique subsets of the problem may imply a partial solution to our task. 

Several methods have been proposed to reward individuals with uniquely good test performance, such as implicit fitness sharing (IFS)~\citep{mckay_investigation_2001}, historically assessed hardness~\citep{klein_genetic_2008}, and co-solvability~\citep{schaefer_using_2010}, all of which assign greater weight to fitness cases that are judged to be more difficult in view of the population performance. Perhaps the most effective parent selection method designed to account for case hardness is lexicase selection~\citep{spector_assessment_2012}. In particular, ``global  pool,  uniform  random  sequence,  elitist  lexicase  selection"~\citep{spector_assessment_2012}, which we refer to simply as lexicase selection, has outperformed other similarly-motivated methods in recent studies~\citep{helmuth_solving_2014, helmuth_general_2015-1, liskowski_comparison_2015}. Despite these gains, it fails to produce such benefits when applied to continuous symbolic regression problems, due to its method of selecting individuals based on training case elitism. For this reason we recently proposed~\citep{la_cava_epsilon-lexicase_2016} modulating the case pass conditions in lexicase selection using an automatically defined $\epsilon$ threshold, allowing the benefits of lexicase selection to be achieved in continuous domains. 

To date, lexicase selection and $\epsilon$-lexicase selection have mostly been analyzed via empirical studies, rather than algorithmic analysis. In particular, previous work has not explicitly described the probabilities of selection under lexicase selection compared to other selection methods, nor how lexicase selection relates to the multi-objective literature. Therefore, the foremost purpose of this paper is to describe analytically how lexicase selection and $\epsilon$-lexicase selection operate on a given population compared to other approaches. With this in mind, in \S\ref{s:prob} we derive an equation that describes the expected probability of selection for individuals in a given population based on their behavior on the training cases, for all variants of lexicase selection. Then in \S\ref{s:mo}, we analyze lexicase and $\epsilon$-lexicase selection from a multi-objective viewpoint, in which we imagine each training case to be an objective. We prove that individuals selected by lexicase selection exist at the boundaries of the Pareto front defined by the program error vectors. We show via an illustrative example population in \S\ref{s:ex} how the probabilities of selection differ under tournament, lexicase, and $\epsilon$-lexicase selection. 

The second purpose of this paper is to empirically assess the use of $\epsilon$-lexicase selection in continuous domains. In \S\ref{s:eplex}, we define two new automated pass conditions in $\epsilon$-lexicase which are shown to improve the method compared to the original implementation: semi-dynamic and dynamic $\epsilon$-lexicase selection. A set of experiments compares variants of $\epsilon$-lexicase selection to several existing selection techniques on a set of real world benchmark problems. The results show that ability of $\epsilon$-lexicase selection to improve the predictive accuracy of models on these problems. We examine in detail the diversity of programs during these runs, as well as the number of cases used in selection events to validate our hypothesis that $\epsilon$-lexicase selection allows for more cases to be used when selecting individuals compared to lexicase selection.   


\section{Preliminaries}
In symbolic regression, we attempt to find a model $\hat{y}(\mathbf{x}): \mathbb{R}^d \rightarrow \mathbb{R}$ that maps variables to a target output using a set of $T$ training examples $\mathcal{T} = \{t_i = (y_i,\mathbf{x}_i)\}_{i=1}^T$, where $\mathbf{x}$ is a $d$-dimensional vector of variables, i.e. features, and $y$ is the desired output. We refer to elements of $\mathcal{T}$ as ``cases". GP poses the problem as
\begin{equation} \label{eq:gp}
\text{minimize} \hspace{0.5em} {f(n,\mathcal{T})} \hspace{1em} \text{subject to} \hspace{0.5em} {n \in \mathfrak{N}}
\end{equation}
where $\mathfrak{N}$ is the space of possible programs $n$ and $f$ denotes a minimized fitness function. GP attempts to solve the symbolic regression task by optimizing a population of $N$ programs $\mathcal{N} = \{n_i\}_{i=1}^N$, each of which encodes a model of the process and produces an estimate  $\hat{y}_t(n,\mathbf{x}_t): \mathbb{R}^d \rightarrow \mathbb{R}$ when evaluated on case $t$. We refer to $\hat{y}(n)$ as the {\it semantics} of program $n$, omitting $\mathbf{x}$ for brevity. We denote the squared differences between $\hat{y}$ and $y$, (i.e., the errors) as $e_t(n) = (y_t - \hat{y}_t(n))^2$.  We use $\mathbf{e}_t \in \mathbb{R}^N$ to refer to the errors of all programs in the population on training case $t$. The lowest error in $\mathbf{e}_t$ is referred to as $e^*_t$. 

A typical fitness measure ($f$) is the mean squared error, $\text{MSE}(n,\mathcal{T}) = \frac{1}{N} \sum_{t \in \mathcal{T}}{e_t(n)}$, which we use to compare our results in \S\ref{s:results}. For the purposes of our discussion, it is irrelevant whether the MSE or the mean absolute error, i.e. MAE$(n,\mathcal{T}) = \frac{1}{N} \sum_{t \in \mathcal{T}}{|y_t - \hat{y}_t(n)|}$, is used, and so we use MAE to simplify a few examples throughout the paper. With lexicase selection and its variants, $e(n)$ is used directly during selection rather than averaging over cases. Nevertheless, in keeping with the problem statement in Eqn.~\ref{eq:gp}, the final program returned in our experiments is that which minimizes the MSE.

%$\mathcal{T} = \{ (y_t,\mathbf{x}_t)\}_{t = 1}^N$, using e.g. the mean absolute error (MAE), which is quantified for individual program $i \in P$ as:
%\begin{equation}
%MSE(\mathcal{T}) = \frac{1}{N} \sum_{t \in \mathcal{T}}{|y_t - \hat{y}_t(\mathbf{x}_t)|} \label{eq:fit} 
%\end{equation}
%
%where $\mathbf{x} \in \mathbb{R}^D$ represents the variables or features, the target output is $y$ and $\hat{y}(i,\mathbf{x})$ is the program's output. As a result of the aggregation of the absolute error vector $e(i) = |y - \hat{y}(i,\mathbf{x})|$ in Eq.~(\ref{eq:fit}), the relationship of $\hat{y}$ to $y$ is represented crudely when choosing models to propagate.

\section{Lexicase Selection}\label{s:lex}
Lexicase selection is a parent selection technique based on lexicographic ordering of training (i.e. fitness) cases. The lexicase selection algorithm for a single selection event is presented below: 

\medskip
\noindent{\footnotesize
\begin{tabularx}{\textwidth}{lX}
\multicolumn{2}{c}{{\normalsize Algorithm 2.1: Lexicase Selection}} \\
\texttt{Selection}($\mathcal{N,T}$, \texttt{ns}) 	:						&	\\
\hspace{1em} $\mathcal{P} \leftarrow \emptyset$ & set of selected parents \\
\hspace{1em} do \texttt{ns} times: & \texttt{ns} is the number of selection events\\
\hspace{1em}  \hspace{1em} $\mathcal{P} \leftarrow \mathcal{P} \; \cup $ \texttt{GetParent}($\mathcal{N,T}$) & add selected program to $\mathcal{P}$ \\
\\
\texttt{GetParent}($\mathcal{N,T}$) 	:						&	\\
\hspace{1em}	$\mathcal{T}' \leftarrow \mathcal{T}$	&	training cases\\
\hspace{1em}	$S \leftarrow \mathcal{N}$	&	initial selection pool is the population\\
\hspace{1em}	while $|\mathcal{T}'| >0$ and $|\mathcal{S}|>1$:						&	main loop\\
\hspace{1em}\hspace{1em}	$t \leftarrow$ random choice from $\mathcal{T'}$ 	&	\hspace{1em}consider a random case\\
\hspace{1em}\hspace{1em}	\texttt{elite} $\leftarrow$ best fitness in $\mathcal{S}$ on $t$ 	&	\hspace{1em}determine elite fitness\\
\hspace{1em}\hspace{1em}	$\mathcal{S} \leftarrow n \in \mathcal{S}$ if fitness($n$, $t$) = \texttt{elite}				&	\hspace{1em}reduce selection pool to elites\\
\hspace{1em}\hspace{1em}	$\mathcal{T'} \leftarrow \mathcal{T'} \setminus \{t\}$ 				&	\hspace{1em}reduce remaining cases\\
\hspace{1em} return random choice from $\mathcal{S}$															&	return parent  
\end{tabularx}
}
\medskip

Algorithm 2.1 is very simple to implement because it consists of just a few steps: 1) choosing a case, 2) filtering the selection pool based on that case, and 3) repeating until the cases are exhausted or the selection pool is reduced to one individual. If the selection pool is not reduced by the time each case has been considered, an individual is chosen randomly from the remaining pool, $\mathcal{S}$. 

Under lexicase selection, cases in $\mathcal{T}$ can be thought of as filters that reduce the selection pool to the individuals in the pool that are best on that case. Each parent selection event constructs a new path through these filters. We refer to individuals as ``passing" a case if they remain in the selection pool when the case is considered. The filtering strength of a case is affected by two main factors: its difficulty as defined by the number of individuals that the case filters from the selection pool, and its order in the selection event, which varies from selection to selection. These two factors are interwoven in lexicase selection because a case performs its filtering on a subset of the population created by a randomized sequence of cases that come before it. In other words, the difficulty of a case depends not only on the problem definition, but on the ordering of the case in the selection event, which is randomized for each selection.

Regarding case difficulty, consider two extreme examples: if a case is passed by the whole population, then it will perform no filtering, resulting in no selection pressure; on the other hand, if a case is passed by a single individual only, then that individual will be selected every time the case is considered for a selection pool containing the individual that passes it. This mechanism allows selective pressure to continually shift to individuals that are elite on cases that are not widely solved in $\mathcal{N}$. Because cases appear in various orderings during selection, there is selective pressure for individuals to solve unique {\it subsets} of cases. Lexicase selection thereby accounts not only for the difficulty of individual cases but the difficulty of solving arbitrarily-sized subsets of cases. This selection pressure leads to the preservation of high behavioral diversity during evolution~\citep{Helmuth:2015:GPTP, la_cava_epsilon-lexicase_2016}. 

The worst-case complexity of selecting $N$ parents per generation with $|\mathcal{T}| = T$ test cases is $O(TN^2)$. This running time stems from the fact that to select a single individual, lexicase selection may have to consider the error value of every individual on every test case.
In contrast, tournament selection only needs to consider the precomputed fitnesses of a constant tournament size number of individuals; thus selecting a single parent can be done in constant time. Since errors need to be calculated and summed for every test case on every individual, tournament selection requires $O(TN)$ time to select $N$ parents.
Normally, due to differential performance across the population and due to lexicase selection's tendency to promote diversity, a lexicase selection event will use many fewer test cases than $T$; the selection pool typically winnows below $N$ as well, meaning the actual running time tends to be better than the worst-case complexity~\citep{helmuth_solving_2014, la_cava_epsilon-lexicase_2016}. 

We use an example population originally presented in~\citep{spector_assessment_2012} to illustrate some aspects of standard lexicase selection in the following sections. The population, shown in Table~\ref{tbl:ex}, consists of five individuals and four training cases with discrete errors. A graphical example of the filtering mechanism of selection is presented for this example in Figure~\ref{fig:lex_graph}. Each lexicase selection event can be visualized as a randomized depth-first pass through the training cases. Figure~\ref{fig:lex_graph} shows four example selection events represented by different line types. The populations are winnowed at each case to the elites until single individuals, shown with diamond-shaped nodes, are selected. 

\begin{table}
\centering
\caption{Example population from original lexicase paper~\citep{spector_assessment_2012}. $P_{lex}$ and $P_t$ are the probabilities of selection under lexicase selection (Eqn.~\ref{eq:prob}) and tournament selection with tournament size 2 (Eqn.~\ref{eq:prob_t}), respectively.}\label{tbl:ex}
\begin{tabular}{l|cccc|c|r|rr}\toprule
Program & \multicolumn{4}{c}{Case Error} & Elite Cases & MAE & $P_{lex}$ & $P_{t}$\\
& $e_1$ & $e_2$ & $e_3$ & $e_4$ & \\ \midrule
$n_1$ & 2 & 2 & 4 & 2 & $\{t_2,t_4\}$ &	2.5		&	0.25 	& 	0.28	\\
$n_2$ & 1 & 2 & 4 & 3 & $\{t_2\}$		&	2.5		&	0.00	&	0.28	\\
$n_3$ & 2 & 2 & 3 & 4 & $\{t_2,t_3\}$ &	2.75	& 	0.33	&	0.12	\\
$n_4$ & 0 & 2 & 5 & 5 & $\{t_1,t_2\}$ &	3.0		& 	0.21	&	0.04	\\
$n_5$ & 0 & 3 & 5 & 2 & $\{t_1,t_4\}$ &	2.5		&	0.21	&	0.28	\\ \bottomrule
\end{tabular}
\end{table}


\begin{figure}[tb]
\centering
  \includegraphics[height = 0.3\textheight]{figs/lex_graph.pdf}
  \caption{A graphical representation of four example parent selections using lexicase selection on the population in Table~\ref{tbl:ex}. The bold, dashed, bold-dashed and dot-dashed lines indicate different selection paths through the training cases in circles. The boxes indicate the selection pool at each step in the process. The diamonds show the individual selected by each selection event.}\label{fig:lex_graph}
\end{figure}

\section{{\large $\epsilon$}-Lexicase Selection}\label{s:eplex}

Lexicase selection has been shown to be effective in discrete error spaces, both for multi-modal problems~\citep{spector_assessment_2012} and for problems for which every case must be solved exactly to be considered a solution~\citep{helmuth_solving_2014, helmuth_general_2015-1}. In continuous error spaces, however, the requirement for individuals to be {\it exactly} equal to the elite error in the selection pool to pass a case turns out to be overly stringent~\citep{la_cava_epsilon-lexicase_2016}. In continuous error spaces and especially for symbolic regression with noisy datasets, it is unlikely for two individuals to have exactly the same error on any training case unless they are (or reduce to) equivalent models. As a result, lexicase selection is prone to conducting selection based on single cases, for which the selected individual satisfies $e_t \equiv e^*_t$, the minimum error on $t$ among $\mathcal{N}$. Selecting on single cases limits the ability of lexicase to leverage case information on subsets of test cases effectively, and can lead to poorer performance than traditional selection methods~\citep{la_cava_epsilon-lexicase_2016}. 

These observations led to the development of $\epsilon$-lexicase selection~\citep{la_cava_epsilon-lexicase_2016}, which modifies lexicase selection by modulating case filtering conditions using an $\epsilon$ threshold criteria. Hand-tuned and automatic variants of $\epsilon$ were proposed and tested. The best performance was achieved by a 'parameter-less' version that defines $\epsilon$ according to the dispersion of errors in the population on each training case using the median absolute deviation statistic:  
\begin{equation}\label{eq:ep}
\epsilon_t = \text{median}(|\mathbf{e}_t - \text{median}(\mathbf{e}_t)|) = \lambda(\mathbf{e}_t)
\end{equation}
Defining $\epsilon$ according to Eqn.~\ref{eq:ep} allows the threshold to adapt to changing performance of the population on each training case. As performance across the population improves for a training case, $\epsilon$ shrinks, thereby modulating the selectivity of a case based on how difficult it is. We choose the median absolute deviation in lieu of the standard deviation statistic for calculating $\epsilon$ because it is more robust to outliers~\citep{pham-gia_mean_2001}. 

We study three implementations of $\epsilon$-lexicase selection in this paper: static, which is the version originally proposed~\citep{la_cava_automatic_2016}; semi-dynamic, in which the elite error is defined relative to the pool; and dynamic, in which both the elite error and $\epsilon$ are defined relative to the current selection pool. 

Static $\epsilon$-lexicase selection can be viewed as a preprocessing step added to lexicase selection in which the program errors are converted to pass/fail based on an $\epsilon$ threshold. This threshold is defined relative to $e^*_t$, the lowest error on test case $t$ over the entire population. We call this static $\epsilon$-lexicase selection because the elite error $e^*_t$ and $\epsilon$ are only calculated once per generation, instead of relative to the current selection pool, as described in Algorithm~3.1.

\medskip
\noindent{\footnotesize
\begin{tabularx}{\textwidth}{lX}
\multicolumn{2}{c}{\normalsize Algorithm 3.1: {Static $\epsilon$-Lexicase Selection}} \\ 
\texttt{Selection}($\mathcal{N,T}$, \texttt{ns}) 	:						&	\\
\hspace{1em} $\mathcal{P} \leftarrow \emptyset$ & set of selected parents \\
\hspace{1em}	$\epsilon \leftarrow \lambda$($\mathbf{e}_t$) for $t \in \mathcal{T}$	&	get $\epsilon$ for each case across population\\
\hspace{1em}	fitness$(n) \leftarrow 1- \mathbb{I}(e_t(n) \leq e^*_t + \epsilon_t)$ for $t \in \mathcal{T}$ and $n \in \mathcal{N}$	&	convert fitness using within-$\epsilon$ pass condition\\
\hspace{1em} do \texttt{ns} times: & \texttt{ns} is the number of selection events\\
\hspace{1em}  \hspace{1em} $\mathcal{P} \leftarrow \mathcal{P} \; \cup $ \texttt{GetParent}($\mathcal{N,T},\epsilon,$ fitness) & add selected program to $\mathcal{P}$ \\
\\
\texttt{GetParent}($\mathcal{N,T},\epsilon,$ fitness) 	:						&	\\
\hspace{1em}	$\mathcal{T}' \leftarrow \mathcal{T}$	&	training cases\\
\hspace{1em}	$S \leftarrow \mathcal{N}$	&	initial selection pool is the population\\

\hspace{1em}	while $|\mathcal{T}'| >0$ and $|\mathcal{S}|>1$:						&	main loop\\
\hspace{1em}\hspace{1em}	$t \leftarrow$ random choice from $\mathcal{T'}$  	&	\hspace{1em}consider a random case\\
\hspace{1em}\hspace{1em}	\texttt{elite} $\leftarrow$ lowest fitness in $\mathcal{S}$ on $t$ 	&	\hspace{1em}determine elite fitness\\
\hspace{1em}\hspace{1em}	$\mathcal{S} \leftarrow n \in \mathcal{S}$ if fitness($n$) $\leq$ \texttt{elite}	&	\hspace{1em}reduce selection pool\\
\hspace{1em}\hspace{1em}	$\mathcal{T'} \leftarrow \mathcal{T'} \setminus \{t\}$ 				&	\hspace{1em}reduce remaining cases\\
\hspace{1em} return random choice from $\mathcal{S}$															&	return parent  
\end{tabularx}
}
\medskip

The indicator function $\mathbb{I}$ used above is zero when false and one when true. Semi-dynamic $\epsilon$-lexicase selection differs from static $\epsilon$-lexicase selection in that the pass condition is defined relative to the best error {\it among the pool} rather than among the entire population $\mathcal{N}$. In this way it behaves more similarly to standard lexicase selection (Algorithm 2.1), except that individuals are filtered out only if they have error more than $e^*_t + \epsilon_t$. It is defined below:

\medskip
\noindent{\footnotesize
\begin{tabularx}{\textwidth}{lX}
\multicolumn{2}{c}{\normalsize Algorithm 3.2: Semi-dynamic $\epsilon$-Lexicase Selection} \\ 
\texttt{Selection}($\mathcal{N,T}$, \texttt{ns}) 	:						&	\\
\hspace{1em} $\mathcal{P} \leftarrow \emptyset$ & set of selected parents \\
\hspace{1em}	$\epsilon \leftarrow \lambda$($\mathbf{e}_t$) for $t \in \mathcal{T}$	&	get $\epsilon$ for each case across population\\
\hspace{1em} do \texttt{ns} times: & \texttt{ns} is the number of selection events\\
\hspace{1em}  \hspace{1em} $\mathcal{P} \leftarrow \mathcal{P} \; \cup $ \texttt{GetParent}($\mathcal{N,T},\epsilon$) & add selected program to $\mathcal{P}$ \\
\\
\texttt{GetParent}($\mathcal{N,T},\epsilon$) 	:						&	\\
\hspace{1em}	$\mathcal{T}' \leftarrow \mathcal{T}$	&	training cases\\
\hspace{1em}	$S \leftarrow \mathcal{N}$	&	initial selection pool is the population\\
\hspace{1em}	while $|\mathcal{T}'| >0$ and $|\mathcal{S}|>1$:						&	main loop\\
\hspace{1em}\hspace{1em}	$t$ $\leftarrow$ random choice from $\mathcal{T'}$ &	\hspace{1em}consider a random case\\
\hspace{1em}\hspace{1em}	\texttt{elite} $\leftarrow$ lowest error in $\mathcal{S}$ on $t$ 	&	\hspace{1em}determine elite fitness\\
\hspace{1em}\hspace{1em}	$\mathcal{S} \leftarrow n \in \mathcal{S}$ if $e_t(n)$ $\leq$ \texttt{elite}$+\epsilon_{t}$	&	\hspace{1em}reduce selection pool\\
\hspace{1em}\hspace{1em}	$\mathcal{T'} \leftarrow \mathcal{T'} \setminus \{t\}$				&	\hspace{1em}reduce remaining cases\\
\hspace{1em} return random choice from $\mathcal{S}$															&	return parent  
\end{tabularx}
}
\medskip

The final variant of $\epsilon$-lexicase selection is dynamic $\epsilon$-lexicase selection, in which both the error and $\epsilon$ are defined among the current selection pool. In this case, $\epsilon$ is defined as 
\begin{equation}\label{eq:epd}
\epsilon_t(\mathcal{S}) = \text{median}(|\mathbf{e}_t(\mathcal{S}) - \text{median}(\mathbf{e}_t(\mathcal{S}))|) = \lambda(\mathbf{e}_t(\mathcal{S}))
\end{equation}
where $\mathbf{e}_t(\mathcal{S})$ is the vector of errors for case $t$ among the current selection pool $\mathcal{S}$. The dynamic $\epsilon$-lexicase selection algorithm is presented below:

\medskip
\noindent{\footnotesize
\begin{tabularx}{\textwidth}{lX}
\multicolumn{2}{c}{\normalsize Algorithm 3.3: Dynamic $\epsilon$-Lexicase Selection} \\ 
\texttt{Selection}($\mathcal{N,T}$, \texttt{ns}) 	:						&	\\
\hspace{1em} $\mathcal{P} \leftarrow \emptyset$ & set of selected parents \\
\hspace{1em} do \texttt{ns} times: & \texttt{ns} is the number of selection events\\
\hspace{1em}  \hspace{1em} $\mathcal{P} \leftarrow \mathcal{P} \; \cup $ \texttt{GetParent}($\mathcal{N,T}$) & add selected program to $\mathcal{P}$ \\
\\
\texttt{GetParent}($\mathcal{N,T}$) 	:						&	\\
\hspace{1em}	$T' \leftarrow \mathcal{T}$	&	training cases\\
\hspace{1em}	$S \leftarrow \mathcal{N}$	&	initial selection pool is the population\\
\hspace{1em}	while $|T'| >0$ and $|\mathcal{S}|>1$:						&	main loop\\
\hspace{1em}\hspace{1em}	$t$ $\leftarrow$ random choice from $\mathcal{T'}$  	&	\hspace{1em}consider a random case\\
\hspace{1em}\hspace{1em}	\texttt{elite} $\leftarrow$ lowest error in $\mathcal{S}$ on $t$ 	&	\hspace{1em}determine elite fitness\\
\hspace{1em}\hspace{1em}	$\epsilon_t \leftarrow \lambda(\mathbf{e}_t(\mathcal{S}))$	&	\hspace{1em}determine $\epsilon$ for case $t$\\
\hspace{1em}\hspace{1em}	$\mathcal{S} \leftarrow n \in \mathcal{S}$ if $e_t(n)$ $\leq$ \texttt{elite}$+\epsilon_{t}$	&	\hspace{1em}reduce selection pool\\
\hspace{1em}\hspace{1em}	$\mathcal{T'} \leftarrow \mathcal{T'} \setminus \{t\}$				&	\hspace{1em}reduce remaining cases\\
\hspace{1em} return random choice from $\mathcal{S}$															&	return parent  
\end{tabularx}
}
\medskip

Since calculating $\epsilon$ according to Eqn.~\ref{eq:ep} is $O(N)$ for a single test case, meaning that the three $\epsilon$-lexicase selection algorithms share a worst-case complexity with lexicase selection of $O(TN^2)$ to select $N$ parents. As discussed in \S\ref{s:lex}, these worst-case time complexities are rare, and empirical results have confirmed $\epsilon$-lexicase to run within the same time frame as tournament selection~\citep{la_cava_epsilon-lexicase_2016}. %, which has a time complexity of $O(TN)$. 

\section{Related Work}\label{s:rw}

Lexicase selection belongs to a class of GP systems that incorporate a program's full semantics directly into the search process, and as such shares a general motivation with recently proposed methods such as Geometric Semantic GP~\citep{moraglio_geometric_2012} and Behavioral GP~\citep{krawiec_behavioral_2014}, despite differing strongly in approach. Instead of incorporating the full semantics, a number of GP methods alter the fitness metric by weighting training cases based on population performance. In non-binary Implicit Fitness Sharing (IFS)~\citep{krawiec_implicit_2013}, for example, the fitness proportion of a case is scaled by the performance of other individuals on that case. Similarly, historically assessed hardness scales error on each training case by the success rate of the population~\citep{klein_genetic_2008}. Discovery of objectives by clustering (DOC)~\citep{krawiec_automatic_2015} clusters training cases by population performance, and thereby reduces training cases into a set of objectives used in multi-objective optimization. Both IFS and DOC were outperformed by lexicase selection on program synthesis and boolean problems in previous studies~\citep{helmuth_general_2015-1,liskowski_comparison_2015}. Other methods attempt to sample a subset of $\mathcal{T}$ to reduce computation time or improve performance, such as dynamic subset selection~\citep{gathercole_dynamic_1994}, interleaved sampling~\citep{goncalves_balancing_2013}, and co-evolved fitness predictors~\citep{schmidt_coevolution_2008}. Unlike these methods, lexicase selection begins each selection with the full set of training cases, and allows selection to adapt to program performance on them.

Although to an extent the ideas of multiobjective optimization apply to multiple training cases, they are qualitatively different and commonly operate at different scales. Objectives and training cases therefore commonly exist at different scales: symbolic regression often involves one or two objectives (e.g. accuracy and model conciseness) and hundreds or thousands of training cases. One example of using training cases explicitly as objectives occurs in~\cite{langdon_evolving_1995} in which small numbers of training cases (in this case 6) are used as multiple objectives in a Pareto selection scheme. Other multi-objective approaches such as NSGA-II~\citep{schoenauer_fast_2000}, SPEA2~\citep{zitzler_spea2:_2001} and ParetoGP~\citep{smits_pareto-front_2005} are used commonly with a small set of objectives in symbolic regression. The ``curse of dimensionality" prevents the use of objectives at the scale of typical training case sizes, since most individuals become nondominated, leading to selection based mostly on diversity measures rather than performance. Scaling issues in many-objective optimization are reviewed by~\cite{ishibuchi_evolutionary_2008}. The connection between lexicase selection and multi-objective methods is discussed in depth in \S\ref{s:mo}.
%Pareto strength in SPEA2 promotes individuals based on how many individuals they dominate, and similarly lexicase selection increases the probability of selection for individuals who solve {\it more} cases and {\it harder} cases (i.e. cases that are not solved by other individuals) and decreases for individuals who solve {\it fewer} or {\it easier} cases. 
 
The conversion of a model's real-valued fitness into discrete values based on an $\epsilon$ threshold has been explored in other research; for example, Novelty Search GP~\citep{martinez_searching_2013} uses a reduced error vector to define behavioral representation of individuals in the population. \cite{la_cava_epsilon-lexicase_2016} it for the first time as a solution to applying lexicase selection effectively to regression.

Recent work has empirically studied and extended lexicase selection.~\cite{helmuth_impact_2016} found that extreme selection events in lexicase selection were not central to its performance improvements and that lexicase selection could re-diversify less-diverse populations unlike tournament selection~\citep{helmuth_effects_2016}. A survival-based version of $\epsilon$-lexicase selection has also been proposed~\citep{la_cava_general_2017,la_cava_ensemble_2017} for maintaining uncorrelated populations in an ensemble learning context. 


\section{Expected Probabilities of Selection}\label{s:prob}
The literature on lexicase selection has yet to analytically address the question: what is the probability of an individual being selected by lexicase selection, given its performance in a population on a set of training cases?  Put into words, the probability of $n$ being selected is the probability that a case $n$ passes is selected and: 1) no more cases remain and $n$ is selected among the set of individuals that pass the selected case; or 2) $n$ is the only individual that passes the case; or 3) $n$ is selected via the selection of another case that $n$ passes (repeating the process). 

Formally, let $P_{lex}(n | \mathcal{N}, \mathcal{T})$ be the probability of $n \in \mathcal{N}$ being selected by lexicase selection. Let $\mathcal{K}_n(\mathcal{T},\mathcal{N}) = \{k_i\}_{i=1}^K \subseteq \mathcal{T}$ be the training cases from $\mathcal{T}$ for which individual $n$ is elite among $\mathcal{N}$. We will use $\mathcal{K}_n$ for brevity. Then the probability of selection under lexicase can be represented as a piece-wise recursive function: 


%{\scriptsize
%\begin{align}\label{eq:prob}
%P_{lex}(n | \mathcal{N}, \mathcal{T}) &= \\
% &\left\{\nonumber 
%     \begin{array}{lcr}
%       1 & : & |\mathcal{T}| >0, |\mathcal{N}| = 1; \\
%       1/|\mathcal{N}| & : &|\mathcal{T}| = 0; \\ 
%       \frac{1}{|\mathcal{T}|}\sum_{k_s \in K_n}{P_{lex} \left( n | \mathcal{N}(m|k_s \in K_m), \mathcal{T}(t|t \neq k_s) \right)} & : & \text{otherwise}
%     \end{array}
%   \right. 
%\end{align}
%}

\begin{equation}\label{eq:prob}
P_{lex}(n | \mathcal{N}, \mathcal{T}) =
\begin{cases}
1 & \text{if } |\mathcal{N}| = 1;\\
1/|\mathcal{N}| & \text{if } |\mathcal{T}| = 0;\\
\frac{1}{|\mathcal{T}|}\sum_{k_s \in K_n}{P_{lex} \left( n | \mathcal{N}(m|k_s \in K_m), \mathcal{T} \setminus \{k_s\} \right)} & \text{otherwise}
\end{cases}
\end{equation}

The first two elements of $P_{lex}$ follow from the lexicase algorithm: if there is one individual in $\mathcal{N}$, then it is selected; otherwise if there no more cases in in $\mathcal{T}$, then $n$ has a probability of selection split among the individuals in $\mathcal{N}$, i.e.,  $1/|\mathcal{N}|$. If neither of these conditions are met, the remaining probability of selection is $1/|\mathcal{T}|$ times the summation of $P_{lex}$ over $n$'s elite cases. Each case in $K_n$ has a probability of $1/|\mathcal{T}|$ of being selected. For each potential selection $k_s$, the probability of $n$ being selected as a result of this case being chosen is dependent on the number of individuals that are also elite on this case, represented by $\mathcal{N}(m|k_s \in K_m)$, and the cases that are left to be traversed, represented by $\mathcal{T} \setminus \{k_s\}$. 

Eqn.~\ref{eq:prob} also describes the probability of selection under $\epsilon$-lexicase selection, with the condition that {\it elitism} on a case is defined as being within $\epsilon$ of the best error on that case, where the best error is defined among the whole population (static) or among the current selection pool (semi-dynamic and dynamic) and $\epsilon$ is defined according to Eqn.~\ref{eq:ep} or Eqn.~\ref{eq:epd}. 

%\paragraph{Intuitions according to edge cases}
According to Eqn.~\ref{eq:prob}, when fitness values across the population are unique, selection probability is $P_{lex}(n) = \frac{1}{|\mathcal{T}|} \sum_{k_s \in \mathcal{K}_n} 1 = \frac{|\mathcal{K}_n|}{|\mathcal{T}|}$, since filtering the population according to any case for which $n$ is elite will result in $n$ being selected. Conversely, if the population semantics are completely homogeneous such that every individual is elite on every case, the selection will be uniformly random, giving the selection probability $P_{lex}(n) = \frac{1}{N}$. This property of uniform random selection for identical performance holds true for individual cases as well: a case $t$ will have no impact on the probability of selection if it is not in any individual's elite set ($K$), or equivalently if $t$ is in every individual's elite set. This intuition is also gleaned from Algorithm 2.1: any case that every individual passes provides no selective pressure because the selection pool does not change when it is selected.

Although it is tempting to pair Eqn.~\ref{eq:prob} with roulette wheel selection as an alternative to lexicase selection, an analysis of its complexity discourages such use. Eqn.~\ref{eq:prob} has a worst-case complexity of $O(T^N)$, which is exhibited when all individuals are elite on $\mathcal{T}$. 
%Lexicase selection can be seen as a way to sample the expected probabilities of each individual by  on random orders of cases in $\mathcal{T}$, considering one at a time rather than branching to consider other combinations of cases that could result in selection for each individual in question. 

 
\subsection{Effect of Population and Training Set Size}

Previous studies have suggested that the performance of lexicase selection is sensitive to the number of training cases~\citep{liskowski_comparison_2015}. In this section we develop the relation of population size and number of training cases to the performance of lexicase selection as a search driver. In part, this behavior is inherent to the design of the algorithm. However, this behavior is also linked to the fidelity with which lexicase selection samples the expected probabilities of selection for each individual in the population. 

The effectiveness of lexicase selection is expected to suffer when there are few training cases. When $T$ is small, there are very few ways in which individuals can be selected. In an extreme case, if $T = 2$, an individual must be elite on one of these two cases to be selected. In fact, in this case individuals with at most 2 different error vectors will be selected. For continuous errors in which few individuals are elite, this means that very few individuals are likely to produce all of the children for the subsequent generation, leading to hyperselection~\citep{helmuth_impact_2016} and diversity loss. On the other hand, if many individuals solve both cases, selection becomes increasingly random. 
%Because $\epsilon$-lexicase modulates the threshold for passing a case, it is likely to be more robust to smaller numbers of cases than lexicase selection since the case depth per selection event is likely to be higher.

The population size is tied to selection behavior because it determines the number of selection events (\texttt{ns} in Algorithms 2.1-3.3). In our implementation, \texttt{ns} = $N$, whereas in other implementations, $N \leq \texttt{ns} \leq 2N$. This implies that the value of $N$ determines the fidelity with which $P_{lex}$ is approximated via the sampling of the population by parent selection. Smaller populations will therefore produce poorer approximations of $P_{lex}$. We illustrate this in our example in \S\ref{s:ex}. Of course, this problem is not unique to lexicase selection; tournament selection also samples from an expected distribution and is affected by the number of tournaments~\citep{xie_another_2007}.  

Both $N$ and $T$ affect how well the expected probabilities of selection derived from Eqn.~\ref{eq:prob} are approximated by lexicase selection. Consider the probability of a case being in at least one selection event in a generation, which is one minus the probability of it not appearing, yielding
\[Pr= 1 - \prod_{i=1}^N{\frac{(T-1)!}{T!(T-1-d_i)!}} \]
Here, the case depth $d_i$ is the number of cases used to select a parent for selection event $i$. Because the case depth varies from selection to selection based on population semantics, this case probability is difficult to analyze. However, it can be simplified to consider the scenario in which a case appears {\it first} in selection. In fact, Eqn.~\ref{eq:prob} implies that a case in $\mathcal{K}_n$ influences the probability of selection of $n$ most heavily when it occurs first in a selection event. There are two reasons: first, the case has the potential to filter $N-1$ individuals, which is the strongest selection pressure it can apply. Second, a case's effect size is highest when selected first because it is not conditioned on the probability of selection of any other cases. Each subsequent case selection has a reduced effect on $P_{lex}$ of $\prod_{i=1}^d{\frac{1}{T-i}}$, where $d$ is the case depth. These observations also highlight the importance of the relative sizes of $N$ and $T$ because they affect the probability that a case will be observed at the top of a selection event in a given generation, which affects how closely Eqn.~\ref{eq:prob} is approximated. Let $P_{\text{first}}$ be the probability that a case will come first in a selection event {\it at least once} in a generation. Then
\begin{equation}\label{eq:prob_case}
P_{\text{first}} = 1 - \left(\frac{(T-1)}{T}\right)^N
\end{equation}
assuming $N$ selection events. This function is plotted for various values of $N$ and $T$ in Figure~\ref{fig:prob_first}, and illustrates that the probability of a case appearing first in selection drops as $T$ grows and as $N$ shrinks. For example, $P_{\text{first}} \approx 0.5$ when $N=1000$ and $T=1433$. We therefore expect the observed probabilities of selection for $n \in \mathcal{N}$ to differ from $P_{lex}(n)$ when $T >> N$, due to insufficient sampling of the cases. In the case of $N >> T$, we expect most cases to appear first and therefore the probability predictions made by Eqn.~\ref{eq:prob} to be more accurate to the actual selections. 

\begin{figure}
\centering
  \includegraphics[width = 0.6\textwidth]{figs/prob_case_first_heatmap.pdf}
  \caption{The probability of a case occuring first in a selection event given $T$ training cases and $N$ selections.}\label{fig:prob_first}
\end{figure}

\subsection{Probabilities under tournament selection} We compare the probability of selection under lexicase selection to that using tournament selection with an identical population and fitness structure. To do so we must first formulate the probability of selection for an individual undergoing tournament selection with size $r$ tournaments. The fitness ranks of $\mathcal{N}$ can be calculated, for example using MAE as fitness, with lower rank indicating better fitness. Let $S_i$ be the individuals in $\mathcal{N}$ with a fitness rank of $i$, and let $Q$ be the number of unique fitness ranks. \cite{xie_another_2007} showed that the probability of selecting an individual with rank $j$ in a single tournament is
\begin{equation}\label{eq:prob_t}
P_t = \frac{1}{|S_j|}\left( \left(\frac{\sum_{i=j}^Q{|S_i|}}{N}\right)^r - \left(\frac{\sum_{i=j+1}^Q{|S_i|}}{N}\right)^r \right)
\end{equation}

In Table~\ref{tbl:ex}, the selection probabilities for the example population are shown according to lexicase selection (Eqn.~\ref{eq:prob}) and tournament selection (Eqn.~\ref{eq:prob_t}). Note that the tournament probabilities are proportional to the aggregate fitness, whereas lexicase probabilities reflect more subtle but intuitive performance differences as discussed by ~\cite{spector_assessment_2012}. In \S\ref{s:ex} we present a more detailed population example with continuous errors and compare probabilities of selection using lexicase, $\epsilon$-lexicase and tournament selection. 
%As an example of calculating absolute probabilities, we consider the illustrative problem from the original lexicase selection paper~\citep{spector_assessment_2012}, shown in Table~\ref{tbl:ex}. Using Eqn.~\ref{eq:prob}, the probabilities for each individual can be calculated as follows:

%\begin{align*}
%P_{lex}(n_1)& = 1/4*(1/3*(1)+1/3*(1+1)) &=& 0.25 \\
%P_{lex}(n_2)& = 1/4*(0) &=& 0 \\
%P_{lex}(n_3)& =1/4*(1/3*(1+1/2*(1))+1/3*(1)) &=& 0.20833 \\
%P_{lex}(n_4)& = 1/4*(1/3*(1/2*(1)+1)+1/3*(1)) &=& 0.20833 
%\end{align*}
%


 

%Here is a detailed look at selection for program $n_1$:
%\begin{align*}
%P_{lex}(n_1 | \mathcal{N}, \mathcal{T}) &= \frac{1}{|\{t_1,t_2,t_3,t_4\}|}  \sum_{k_s \in \{t_2,t_4\}}{ P_{lex} \left( n_1 | \mathcal{N}(m|k_s \in K_m(\mathcal{T})), \mathcal{T}(t|t \neq k_s) \right)}  \\
%&= \frac{1}{4} \biggl[ P_{lex} \left( n_1 | \mathcal{N}(m|t_2 \in K_m(\mathcal{T})), \mathcal{T}(t|t \neq t_2) \right) + P_{lex} \left( n | \mathcal{N}(m|t_4 \in K_m(\mathcal{T})), \mathcal{T}(t|t \neq t_4) \right) \biggl] \\
%&= \frac{1}{4} \left[ P_{lex} ( n | \{n_1, n_2, n_3, n_4\}, \{t_1, t_3, t_4\} ) + P_{lex} ( n | \{n_1, n_5 \} , \{t_1, t_2, t_3\} ) \biggl] \\
%&= \frac{1}{4} \biggl[ \frac{1}{|\{t_1, t_3, t_4\}} \sum_{k_s \in \{t_4\}}{ P_{lex} \left( n | \mathcal{N}(m|k_s \in K_m(\mathcal{T}(t|t \neq t_2)), \mathcal{T}(t|t \notin \{t_2,k_s\}) \right)} \\
%& + \frac{1}{|\{t_1, t_2, t_3\}|} \sum_{k_s \in \{t_2,t_3\}}{ P_{lex} \left( n | \mathcal{N}(m|k_s \in K_m(\mathcal{T}(t|t \neq t_2)), \mathcal{T}(t|t \notin \{t_4,k_s\}) \right)}\biggl] \\
%&= \frac{1}{4} \biggl[ \frac{1}{3} P_{lex} ( n_1 | \{n_1\}, \{t_1, t_3\})  + \frac{1}{3} \biggl( P_{lex} ( n_1 | \{n_1\}, \{t_1,t_3\} ) \\
%&+ P_{lex} ( n_1 | \{n_1\}, \{t_1,t_2\} ) \biggl) \biggl]\\
%&= \frac{1}{4} \biggl[ \frac{1}{3}(1) + \frac{1}{3}(1 + 1) \biggl]\\
%&= \frac{1}{4} 
%\end{align*}

\section{Multi-objective Interpretation of Lexicase Selection}\label{s:mo}

Objectives and training cases are fundamentally different entities: objectives define the goals of the task being learned, whereas cases are the units by which progress towards those objectives is measured. By this criteria, lexicase selection and multi-objective optimization have historically been differentiated~\citep{helmuth_general_2015}, although there is clearly a ``multi-objective" interpretation of the behavior of lexicase selection with respect to the training cases. Let us assume for the remainder of this section that individual fitness cases are objectives to solve. The symbolic regression task then becomes a high-dimensional, many-objective optimization problem. At this scale, the most popular multi-objective methods (e.g. NSGA-II and SPEA-2) tend to perform poorly, a behavior that has been explained in literature~\citep{wagner_pareto-_2007, farina_optimal_2002}. \cite{farina_optimal_2002} point out two short-comings of these multi-objective methods when many objectives are considered: \begin{quote}
the Pareto definition of optimality in a multi-criteria decision making problem can be unsatisfactory due to essentially two reasons: the number of improved or equal objective values is not taken into account, the (normalized) size of improvements is not taken into account.
\end{quote}

As we describe in \S\ref{s:prob}, lexicase selection takes into account the number of improved or equal objectives (i.e. cases) by increasing the probability of selection for individuals who solve more cases (consider the summation in the third part of Eqn.~\ref{eq:prob}). The increase per case is proportional to the difficulty of that case, as defined by the selection pool's performance. Regarding Farina and Amato's second point, the {\it size} of the improvements are taken into account by $\epsilon$-lexicase selection. They are taken into account by the automated thresholding performed by $\epsilon$ which rewards individuals for being within an acceptable range of the best performance on the case. We develop the relationship between lexicase selection and Pareto optimization in the remainder of this section. 

It has been noted lexicase selection guarantees the return of individuals that are on the Pareto front with respect to the fitness cases~\citep{la_cava_epsilon-lexicase_2016}. However, this is a necessary but not sufficient condition for selection. As we show below, lexicase selection only selects those individuals in the ``corners" or boundaries of the Pareto front, meaning they are on the front {\it and} elite, globally, with respect to at least one fitness case. Below, we define these Pareto relations with respect to the training cases. 

\begin{defn}\label{def:dom}
$n_1$ {\it dominates} $n_2$, i.e., ${n_1} \prec {n_2}$, if $e_j(n_1) \leq e_j(n_2) \;
\forall j  \in \{1,\dots,T\}$ and $\exists j \in \{1,\dots,T\}$ for which $e_j(n_1) < e_j(n_2)$. \bigskip
\end{defn}

\begin{defn}\label{def:pset}
The {\it Pareto set} of $\mathcal{N}$ is the subset of $\mathcal{N}$ that is non-dominated with respect to $\mathcal{N}$; i.e., $n \in \mathcal{N}$ is in the Pareto set if $m \nprec n \; \forall \; m \in \mathcal{N}$. 
\end{defn}

\begin{defn}\label{def:boundary}
$n \in \mathcal{N}$ is a {\it Pareto set boundary} if $n \in$ Pareto set of $\mathcal{N}$ and $\exists j \in \{1,\dots,T\}$ for which $e_j(n) \leq e_j(m) \; \forall \; m \in \mathcal{N}$. 
\end{defn}

With these definitions in mind, we show that individuals selected by lexicase are on the Pareto set boundaries. 

\begin{lex}\label{thm:lex}
If individuals from a population $\mathcal{N}$ are selected by lexicase selection, those individuals are Pareto set boundaries of $\mathcal{N}$ with respect to $\mathcal{T}$. 
\end{lex}

\noindent \textit{Proof:} First, we prove (by supposing a contradiction) that individuals selected by lexicase are in the Pareto set. Second, we prove these individuals to be Pareto set boundaries. 

First:  Let $n_1 in \mathcal{N}$ be any individual and let $n_2$ $\in \mathcal{N}$ be an individual selected from $\mathcal{N}$ by lexicase selection. Suppose $n_1 \prec n_2$. Then $e_j(n_1) \leq e_j(n_2) \;
\forall j  \in \{1,\dots,T\}$ and $\exists j \in \{1,\dots,T\}$ for which $e_j(n_1) < e_j(n_2)$. Therefore $n_1$ remains in the selection pool for every case that $n_2$ does, yet $\exists t \in \mathcal{T}$ for which $n_2$ is removed from every selection event due to $n_1$. Hence, $n_2$ cannot be selected by lexicase selection and the supposition is false. Therefore $n_1$ and $n_2$ must be in the Pareto set of $\mathcal{N}$. 

Second: let $n \in \mathcal{N}$ be an individual selected from $\mathcal{N}$ by lexicase selection. Then by definition of Algorithm 2.1, $\exists j \in \{1,\dots,T\}$ for which $e_j(n) \leq e_j(m) \; \forall \; m \in \mathcal{N}$. Therefore, since $n$ is in the Pareto set of $\mathcal{N}$, according to Definition~\ref{def:boundary}, $n$ is a Pareto set boundary of $\mathcal{N}$.  
\bigskip



\subsection{Extension to $\epsilon$-lexicase selection}
We can extend our multi-objective analysis to $\epsilon$-lexicase selection for conditions in which $\epsilon$ is pre-defined for each fitness case  (Eqn.~\ref{eq:ep}), which is true for static and semi-dynamic $\epsilon$-lexicase selection. However when $\epsilon$ is recalculated for each selection pool, the theorem is not as easily extended due to the need to account for the dependency of $\epsilon$ on the current selection pool. We first define $\epsilon$ elitism in terms of a relaxed dominance relation and a relaxed Pareto set. We define the dominance relation with respect to $\epsilon$ as follows:


\begin{defn}\label{def:edom}
$n_1$ {\it $\epsilon$-dominates} $n_2$, i.e., ${n_1} \prec_{\epsilon} {n_2}$, if $e_j(n_1) + \epsilon_j \leq e_j(n_2)  \;
\forall j  \in \{1,\dots,T\}$ and $\exists j \in \{1,\dots,T\}$ for which $e_j(n_1) + \epsilon_j < e_j(n_2) $, where $\epsilon_j>0$ is defined according to Eqn.~\ref{eq:ep}.
\end{defn}


This definition of $\epsilon$-dominance differs from a previous $\epsilon$-dominance definition used by~\cite{laumanns_archiving_2002} (cf. Eqn. (6)) in which ${n_1} \prec_{\epsilon} {n_2}$ if \[ e_j(n_1) + \epsilon_j \leq e_j(n_2) \; \forall \; j  \in \{1,\dots,T\}\] 
Definition~\ref{def:edom} is more strict, requiring $e_j(n_1) + \epsilon_j < e_j(n_2)$ for at least one $j$ in analagous fashion to Definition~\ref{def:dom}.  In order to extend Theorem~\ref{thm:lex}, this definition must be more strict since a useful $\epsilon$-dominance relation needs to capture the ability of an individual to preclude the selection of another individual under $\epsilon$-lexicase selection. 
%As a result, the non-$\epsilon$-dominated set, defined as the $\epsilon$-Pareto set below, is expected to be as large or larger than the $\epsilon$-approximate Pareto set used in~\citep{laumanns_archiving_2002}. 
 
\begin{defn}\label{def:epset}
The {\it $\epsilon$-Pareto set} of $\mathcal{N}$ is the subset of $\mathcal{N}$ that is non-$\epsilon$-dominated with respect to $\mathcal{N}$; i.e., $n \in \mathcal{N}$ is in the $\epsilon$-Pareto set if $m \nprec_{\epsilon} n \; \forall \; m \in \mathcal{N}$. 
\end{defn}

\begin{defn}\label{def:eboundary}
$n \in \mathcal{N}$ is an {\it $\epsilon$-Pareto set boundary} if $n$ is in the $\epsilon$-Pareto set of $\mathcal{N}$ and $\exists j \in \{1,\dots,T\}$ for which $e_j(n_1) \leq e_j(m)+ \epsilon_j \; \forall \; m \in \mathcal{N}$, where $\epsilon_j$ is defined according to Eqn~\ref{eq:ep}. \bigskip
\end{defn}

\begin{lex}\label{thm:eplex}
If $\epsilon$ is defined according to Eqn.~\ref{eq:ep}, and if individuals are selected from a population $\mathcal{N}$ by $\epsilon$-lexicase selection, then those individuals are $\epsilon$-Pareto set boundaries of $\mathcal{N}$.  
\end{lex}


\begin{proof}
First: Let $n_1 in \mathcal{N}$ be any individual and let $n_2$ $\in \mathcal{N}$ be an individual selected from $\mathcal{N}$ by static or semi-dynamic $\epsilon$-lexicase selection. Suppose $n_1 \prec_{\epsilon} n_2$. Therefore $n_1$ remains in the selection pool for every case that $n_2$ does, yet $\exists t \in \mathcal{T}$ for which $n_2$ is removed from every selection event due to $n_1$. Hence, $n_2$ cannot be selected by lexicase selection and the supposition $n_1 \prec_{\epsilon} n_2$ is false.  Therefore $n_1$ and $n_2$ must be in the $\epsilon$-Pareto set of $\mathcal{N}$ to be selected. 

Second: let $n$ be an individual selected from population $\mathcal{N}$ by static or semi-dynamic $\epsilon$-lexicase selection. Then by definition of Algorithm 3.1 or 3.2, $\exists j \in \{1,\dots,T\}$ for which $e_j(n) \leq e_j(m) \; \forall \; m \in \mathcal{N}$. Since $n$ is in the $\epsilon$-Pareto set of $\mathcal{N}$ and according to Definition~\ref{def:eboundary}, $n$ must be a $\epsilon$-Pareto set boundary of $\mathcal{N}$.  
\end{proof}
\bigskip

The selection of Pareto set boundaries by lexicase selection is illustrated in left plot of Figure~\ref{fig:lex_pareto} for a scenario with two fitness cases. Each point in the plot represents an individual, and the squares are the Pareto set. Under a lexicase selection event with case sequence $\{t_1, t_2\}$, individuals would first be filtered to the two left-most individuals that are elite on $e_1$, and then to the individual among those two that is best on $e_2$, i.e. the selected square individual. Note that the selected individual is a Pareto set boundary. The individual on the other end of the Pareto set shown as a black square would be selected using the opposite order of cases.  

Consider the analogous case for semi-dynamic $\epsilon$-lexicase selection illustrated in the right plot of Figure~\ref{fig:lex_pareto}. In this case the Pareto set is indicated by squares that also belong to the $\epsilon$-Pareto set, indicated by circles with dotted lines. Under a semi-dynamic $\epsilon$-lexicase selection event with case order $\{t_1, t_2\}$, the population would first be filtered to the four left-most individuals that are within $\epsilon_1$ of the elite error on case $t_1$, and then the indicated square would be selected by being the only individual within $\epsilon_2$ of the elite error on $t_2$ among the current pool. Note that that although the selected individual is an $\epsilon$-Pareto set boundary by Definition~\ref{def:eboundary}, it is {\it not} a boundary of the Pareto set. Theorem~\ref{thm:eplex} only guarantees that the selected program is within $\epsilon$ of the best error for at least one case, which in this scenario is $t_1$. 

Comparing the left and right plots of Figure~\ref{fig:lex_pareto} illustrates the effect of introducing $\epsilon$ to the filter conditions in lexicase: it reduces the selectivity of each case, ultimately resulting in the selection of individuals that are not as extremely positioned in objective space. Regarding the position of solutions in this space, it's worth noting the significance of boundary solutions (and near boundary solutions) in the context of multi-objective optimization. Boundary solutions are known to contribute significantly to hypervolume measures~\citep{deb_evaluating_2005}, where the hypervolume is a measure of how well-covered the objective space is by the current set of solutions. The boundary solutions have an infinite score according to NSGA-II's crowding measure~\citep{schoenauer_fast_2000}, with higher being better, meaning they are the first non-dominated solutions to be preserved by selection when the population size is reduced. Nonetheless, multi-objective literature appears divided on how these boundary solutions drive search when the goal of the algorithm is to approximate the optimal Pareto front~\citep{wagner_pareto-_2007}. The goal of GP, in contrast, is to preserve points in the search space that, when combined and varied, yield a single best solution. So while the descriptions above lend insight to the function of lexicase and $\epsilon$-lexicase selection, the different goals of search and the high dimensionality of training cases must be remembered when comparing to multi-objective optimization. 

As a last note, when considered as objectives, the worst-case complexity of lexicase selection matches that of NSGA-II: $O(TN^2)$. Interestingly, the worst case complexity of the crowding distance assignment portion of NSGA-II, $O(TN\log(N))$, occurs when all individuals are non-dominated, which is expected in high dimensions~\citep{farina_optimal_2002, wagner_pareto-_2007}. Under lexicase selection, a non-dominated population {\it that is semantically unique} yields the minimum complexity scenario of $O(N^2)$. 

\begin{figure}[htb]

\begin{minipage}{0.49\textwidth}
\centering
  \includegraphics[width = \textwidth]{figs/lex_pareto.pdf}
  %\caption{An illustration of the performance of lexicase selection in a scenario involving two cases. Each point represents and individual in the population. The squares are individuals in the Pareto set. A selection event for case sequence $\{t_1,t_2\}$ is shown by the gray rectangles. The black points are individuals that could be selected by any case ordering.}\label{fig:lex_pareto}
%\end{figure}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.49\textwidth}
%\begin{figure}
\centering
  \includegraphics[width = \textwidth]{figs/ep-lex_pareto.pdf}
  
\end{minipage}
\caption{An illustration of the performance of lexicase selection (left) semi-dynamic $\epsilon$-lexicase selection (right) in a scenario involving two cases. Each point represents and individual in the population. The squares are individuals in the Pareto set, and the circles with dotted lines are individuals in the $\epsilon$-Pareto set (the $\epsilon$-Pareto set also includes the squares). A selection event for case sequence $\{t_1,t_2\}$ is shown by the gray rectangles. The black points are individuals that could be selected by any case ordering.}\label{fig:lex_pareto}
\end{figure}

%\paragraph{Relation to Evolutionary Multi-objective Optimization}
%
%There is an interesting relationship to be made regarding the complexity of lexicase selection in comparison to NSGA-II. Consdering training cases as objectives, we see that lexicase selection and NSGA-II have the same worst-case complexity of $O(T^2N)$. However the algorithms differ with respect to the conditions under which worst case complexities arise. 
%
%NSGA-II has three main parts: sorting ($O(TN^2)$), crowding distance assignment $O(TN \log(N))$, and sorting with crowding comparison $O(2Nlog(2N))$, giving an overall complexity of $O(TN^2$). The sorting complexity is $O(TN^2)$ to identify a single front; the crowding distance assignment complexity varies, however. Its worst case complexity arises when all individuals are non-dominated, which is expected in high dimensions~\citep{farina_optimal_2002, wagner_pareto-_2007}. 
%
%Interestingly, {\it if the population is unique}, this is the minimum complexity scenario for lexicase selection: in other words, if the semantics of the population are unique and all are non-dominated in $\mathcal{T}$, only case depth 1 selections will occur, giving a run-time complexity of $O(N^2)$. Of course, the population could also be non-dominated by being semantically identical, in which case the complexity would be $O(TN^2)$. The important thing to note is that lexicase selection, which rewards individuals for being diverse, also runs more quickly when the population is more diverse. 


\section{Illustrative Example}\label{s:ex}

\begin{table}
\centering
\scriptsize
\caption{Example population with training case performances and selection probabilities according to the different algorithms.}\label{tbl:ex2}
\rowcolors{1}{white}{LightCyan}
\begin{tabularx}{\textwidth}{X|rrrrr|r|R{2em}R{2em}R{2em}R{2em}R{2em}}\toprule
$\mathcal{N}$ & \multicolumn{5}{c}{Cases} & Mean & \multicolumn{5}{c}{Probability of Selection} \\
& $e_1$ & $e_2$ & $e_3$ & $e_4$ & $e_5$ &&	tourn	&	lex	&	$\epsilon$ lex static	&	$\epsilon$ lex semi	&	$\epsilon$ lex dyn\\ \midrule
$n_1$	&0.0	&	1.1	&	2.2	&	3.0	&	5.0 & 2.26	&	0.111	&	0.200	&	0.000	&	0.067	&	0.033\\ 
$n_2$	&0.1	&	1.2	&	2.0	&	2.0	&	6.0 & 2.26	&	0.111	&	0.000	&	0.150	&	0.117	&	0.200\\ 
$n_3$	&0.2	&	1.0	&	2.1	&	1.0	&	7.0 & 2.26	&	0.111	&	0.000	&	0.150	&	0.117	&	0.117\\ 
$n_4$	&1.0	&	2.1	&	0.2	&	0.0	&	8.0 & 2.26	&	0.111	&	0.200	&	0.300	&	0.200	&	0.167\\ 
$n_5$	&1.1	&	2.2	&	0.0	&	4.0	&	4.0 & 2.26	&	0.111	&	0.200	&	0.000	&	0.050	&	0.050\\ 
$n_6$	&1.2	&	2.0	&	0.1	&	5.0	&	3.0 & 2.26	&	0.111	&	0.000	&	0.000	&	0.050	&	0.033\\ 
$n_7$	&2.0	&	0.1	&	1.2	&	6.0	&	2.0 & 2.26	&	0.111	&	0.000	&	0.133	&	0.133	&	0.133\\ 
$n_8$	&2.1	&	0.2	&	1.0	&	7.0	&	1.0 & 2.26	&	0.111	&	0.000	&	0.133	&	0.133	&	0.217\\ 
$n_9$	&2.2	&	0.0	&	1.1	&	8.0	&	0.0 & 2.26	&	0.111	&	0.400	&	0.133	&	0.133	&	0.050\\  \midrule
$\epsilon$	&	0.9	& 0.9	&	0.9	&	2.0	& 2.0	&&&&&&\\ \bottomrule
\end{tabularx}
\end{table}

Here we apply the concepts from \S\ref{s:prob} to illustrate the probabilities of selection under different methods. An example population is presented in Table~\ref{tbl:ex2} featuring floating point errors, in contrast to Table~\ref{tbl:ex}. In this case, the population semantics are completely unique, although they result in the same mean error across the training cases, as shown in the ``Mean" column. As a result, tournament selection picks uniformly from among these individuals, resulting in equivalent probabilities of selection. As mentioned in \S\ref{s:prob}, with unique populations, lexicase selection is proportional to the number of cases for which an individual is elite. This leads lexicase selection to pick from among the four individuals that are elite on cases, i.e. $n_1$, $n_4$, $n_5$, and $n_9$, with respective probabilities 0.2, 0.2, 0.2, and 0.4. 

Due to its strict definition of elitism, lexicase selection does not account for the fact other individuals are very close to being elite on these cases as well; for example $n_2$ and $n_3$ are close to the elite error on case $t_1$. The $\epsilon$-lexicase variants address this as noted by the smoother distribution of selection probabilities among this population. We focus first on static $\epsilon$-lexicase selection. Applying the $\epsilon$ threshold to the errors yields the following discrete fitnesses:

\begin{center}
\begin{tabular}{lrrrrr}
& $e_1$ & $e_2$ & $e_3$ & $e_4$ & $e_5$ \\
$n_1$	&0	&	1	&	1	&	1	&	1\\ 
$n_2$	&0	&	1	&	1	&	0	&	1\\ 
$n_3$	&0	&	1	&	1	&	0	&	1\\ 
$n_4$	&1	&	1	&	0	&	0	&	1\\ 
$n_5$	&1	&	1	&	0	&	1	&	1\\ 
$n_6$	&1	&	1	&	0	&	1	&	1\\ 
$n_7$	&1	&	0	&	1	&	1	&	0\\ 
$n_8$	&1	&	0	&	1	&	1	&	0\\ 
$n_9$	&1	&	0	&	1	&	1	&	0\\ 
\end{tabular}
\end{center}
 
The selection probabilities for static $\epsilon$-lexicase selection are equivalent to the selection probabilities of lexicase selection on this converted error matrix. Despite elitism on case $t_1$, $n_1$ is not selected since $n_2$ and $n_3$ are $\epsilon$-elite on this case {\it in addition to} $t_4$. Consider $n_4$, which has a higher probability of selection under static $\epsilon$-lex than lexicase selection. This is due to $n_4$ being $\epsilon$-elite on a unique combination of cases: $t_3$ and $t_4$. Lastly $n_8$ is selected in equal proportions to $n_7$ and $n_6$ because all three are within $\epsilon$ of the elite error on the same cases. 

Semi-dynamic $\epsilon$-lexicase selection allows for all nine individuals to be selected with varying proportions that are similar to those derived for static $\epsilon$-lexicase selection. Selection probabilities for $n_1$ illustrate the differences in the static and semi-dynamic variants: $n_1$ has a chance for selection in the semi-dynamic case because when $t_1$ is selected as the first case, $n_1$ is within $\epsilon$ of the best case errors {\it among the pool}, i.e. $\{n_1$, $n_2$, $n_3\}$, for any subsequent order of cases. The probability of selection for $n_5$ and $n_6$ follow the same pattern.

Dynamic $\epsilon$-lexicase selection produces the most differentiated selection pressure for this example. Consider individual $n_8$ which is the most likely to be selected for this example. It is selected more often than $n_7$ or $n_9$ due to the adaptations to $\epsilon$ as the selection pool is winnowed. For example, $n_8$ is selected by case sequence $\{t_2,t_1,t_3\}$, for which the selection pool takes the following form after each case: $\{n_7, n_8, n_9\}, \{n_7, n_8\}, \{n_8\}$. Under the other semi-dynamic $\epsilon$-lexicase selection, $n_7$ and $n_8$ would not be removed by these cases due to the fixed nature of $\epsilon$ for those cases. 

The expected probabilities of selection for the population in Table~\ref{tbl:ex2} is shown graphically in Figure~\ref{fig:prob} and visually confirms the similarities in probabilities of selection for the $\epsilon$-lexicase variants, especially semi-dynamic and dynamic variants. The expected probability of selection for semi-dynamic $\epsilon$-lexicase and tournament selection are compared to measured probabilities of selection in Figures~\ref{fig:prob_converge_eplex} and~\ref{fig:prob_converge_tourn}, respectively. 100 trials of a series of 500 selections are conducted, and the probabilities of selection are reported for each individual after each selection event. These figures illustrate that the probabilities of selection converge on the analytical predictions provided by Eqn.~\ref{eq:prob} and Eqn.~\ref{eq:prob_t}, but that the observed probability of selection is sensitive to the number of selection events for both selection methods. We use population sizes of 1000 in our experiments in \S\ref{s:exp}, which should provide adequate sampling to converge to approximately the expected probabilities of selection. 

\begin{figure}
\centering
  \includegraphics[height = 0.4\textheight]{figs/probabilities.pdf}
  \caption{A graphical representation of the probabilities of selection for the population in Table~\ref{tbl:ex2} according to different selection methods.}\label{fig:prob}
\end{figure}


\begin{figure}
\begin{minipage}{0.49\textwidth}
\centering
  \includegraphics[width=\textwidth]{figs/eplex_semi_probability_convergence_500selections.pdf}
  \caption{Selection probabilities for semi-dynamic $\epsilon$-lexicase selection on the example population in Table~\ref{tbl:ex2}. The black line indicates the expected probability of selection according to Eqn.~\ref{eq:prob}. The blue lines are measured probabilities of selection after several selection events. 100 trials of 500 selections are shown.} \label{fig:prob_converge_eplex}
%\end{figure}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.49\textwidth}

%\begin{figure}
\centering
  \includegraphics[width=\textwidth]{figs/tournament_probability_convergence_500selections.pdf}
  \caption{Selection probabilities for tournament selection on the example population in Table~\ref{tbl:ex2}. The black line indicates the expected probability of selection according to Eqn.~\ref{eq:prob_t}. The blue lines are measured probabilities of selection after several selection events. 100 trials of 500 selections are shown.} \label{fig:prob_converge_tourn}
  \end{minipage}
\end{figure}



\section{Experimental Analysis} \label{s:exp}
In this section we empirically test the variants of $\epsilon$-lexicase selection introduced in \S\ref{s:eplex}. The problems studied in this section are listed in Table~\ref{tbl:regression}. We benchmark nine methods using eight different datasets. Six of the problems are available from the UCI repository~\citep{lichman_uci_2013}. The UBall5D problem is a simulated equation\footnote{UBall5D is also known as Vladislavleva-4.} which has the form \[ y = \frac{10}{5+\sum_{i=1}^5{(x_i-3)^2}}\] The Tower problem and UBall5D were chosen from the benchmark suite suggested by \cite{white_better_2012}. 

We compare eight different selection methods: random selection, tournament selection, lexicase selection, age-fitness pareto optimization~\citep{schmidt_age-fitness_2011}, deterministic crowding~\citep{mahfoud_niching_1995}, and the three $\epsilon$-lexicase selection methods presented in \S\ref{s:eplex}. In addition to the selection methods that are benchmarked, we include a comparison to regularized linear regression using Lasso~\citep{tibshirani_regression_1996}. These methods are described briefly below, along with their abbreviations used in the results.

\begin{itemize}
\item Random Selection (rand): selection for parents is random.
\item Tournament Selection (tourn): size two tournaments are conducted for choosing parents. 
\item Lexicase Selection (lex): see Algorithm 2.1. 
\item Age-fitness Pareto optimization (afp): this method introduces a new individual each generation with an age of 0. Each generation, individuals are assigned an age equal to the number of generations since their oldest ancestor entered the population. Parents are selected randomly to create $N$ children. The children and parents then compete in survival tournaments of size two, in which an individual is culled from the population if it is dominated in terms of age and fitness by its competitor. 
\item Deterministic crowding (dc): A generational form of this niching method is used in which parents are selected randomly for variation and the child competes to replace the parent with which it is most similar. Similarity is determined based on the Levenshtein distance of the parent's equation forms, using a universal symbol for coefficients. A child replaces its parent in the population only if it has a better fitness.
\item Static $\epsilon$-lexicase selection (ep-lex-s): See Algorithm 3.1.
\item Semi-dynamic $\epsilon$-lexicase selection (ep-lex-sd): See Algorithm 3.2.
\item Dynamic $\epsilon$-lexicase selection (ep-lex-d): See Algorithm 3.3.
\item Lasso (lasso): this method incorporates a regularization penalty into least squares regression using an $\ell_1$ measure of the model coefficients and uses a tuning parameter, $\lambda$, to specify the weight of this regularization. We use a least angle regression~\citep{efron_least_2004} implementation of Lasso that automatically chooses $\lambda$ using cross validation.
\end{itemize} 

The settings for the GP system\footnote{available from \url{https://epistasislab.github.io/ellyn/}} are shown in Table~\ref{tbl:symreg_settings}. We conduct 50 trials of each method by training on a random partition of 70\% of the dataset and comparing the prediction error of the best model from each method on the other 30\% of the dataset. In addition to test error, we compare the training convergence of the GP-based methods, the semantic diversity of the populations during the run, and the number of cases used for selection for the lexicase methods. We calculate population diversity as the fraction of unique semantics in the population, i.e. 
\begin{equation}\label{eq:diversity}
\text{diversity}(\mathcal{N}) = \frac{1}{N^2}\sum_{i \in \mathcal{N}}{\sum_{j \in \mathcal{N}}{\mathbb{I}[\hat{y}(n_i) \neq \hat{y}(n_j)]}} 
\end{equation}
To compare the number of cases used in selection for the lexicase methods, we save the median number of cases used in selection events, i.e. the case depth, each generation. 
 
\begin{table}
\scriptsize
\caption{GP settings.}\label{tbl:symreg_settings}
\begin{tabularx}{\columnwidth}{X R{0.57\columnwidth}} \toprule
Setting& Value \\ \midrule
Population size & 1000 \\
Crossover / mutation & 60/40\% \\
Program length limits & [3, 50] \\ 
ERC range & [-1,1] \\
Generation limit & 1000 \\
Trials & 50 \\
Terminal Set & \{$\mathbf{x}$, ERC, $+$, $-$, $*$, $/$, $\sin$, $\cos$, $\exp$, $\log$\}\\
Elitism & keep best \\ \bottomrule
\end{tabularx}
\end{table}
\begin{table}
\scriptsize
\caption{Regression problems used for method comparisons.}\label{tbl:regression}
\begin{tabularx}{\columnwidth}{X r r } \toprule
Problem & Dimension & Samples \\ \midrule
Airfoil & 5	& 1503 \\
Concrete	& 	8	& 1030	\\
%Crime	&	127	&	1993	\\
ENC & 8 & 768 \\
ENH & 8 & 768 \\
Housing & 14 & 506 \\
Tower & 25 & 3135 \\
UBall5D & 5 & 6024 \\ 
Yacht	& 6	&	309	\\ \midrule
\end{tabularx}
\end{table}


%\begin{table}
%\scriptsize
%\caption{Dynamical systems used for method comparisons. The systems were simulated four times using initial conditions within stable basins of attraction. $\gamma$ indicates zero-mean, unit-variance Gaussian noise. }\label{tbl:ode}
%\rowcolors{4}{white}{LightCyan}
%\begin{tabularx}{\columnwidth}{L{0.25\columnwidth} L{0.3\columnwidth} L{0.19\columnwidth}  R{0.1\columnwidth}} 
%Problem & Equations & Initial Conditions	& Samples \\ \midrule
%Bacterial Respiration & $\dot{x} = 20 - x - \frac{x \cdot y}{1+0.5 \cdot x^2}$ , $ \dot{y} = 10 - \frac{x \cdot y}{1+0.5 \cdot x^2}$	& $x_0=5 \pm \gamma$, $y_0=10 \pm 0.1\gamma$ & 400 \\
%Bar Magnets & $\dot{\theta} = 0.5 \cdot \sin (\theta - \phi) - \sin (\theta)$,  $ \dot{\phi} = 0.5 \cdot \sin (\phi - \theta) - \sin (\phi)$	&  $\theta_0 \in [-2\pi,2\pi]$, $\phi_0 \in [-2\pi,2\pi]$ & 400 \\
%Glider & $\dot{v} = - 0.05 \cdot  v^2 - sin (\theta)$	, $ \dot{\theta} = v - \cos (\theta)/v$	& $v_0=5 \pm \gamma$, $\theta_0=10 \pm 0.1\gamma$ & 400 \\
%Lotka-Volterra interspecies dynamics & $\dot{x} = 3  \cdot x - 2  \cdot x \cdot y - x^2$, $ \dot{y} = 2 \cdot y - x \cdot y - y^2$	&  $x_0=[1,4,8,3]$, $y_0 = [3, 1, 2, 3]$ & 400 \\
%Predator Prey & $\dot{x} = x  \cdot \left( 4 - x - \frac{y}{1+x} \right)$, $ \dot{y} = 2 \cdot y - x \cdot y - y^2$ 	& $x_0=5 \pm \gamma$, $y_0=10 \pm 0.1\gamma$  & 400 \\
%Shear Flow & $\dot{\theta} = \cot (\phi) \cdot cos(\theta)$, $ \dot{\phi} = \left(\cos ^2 (\phi) + 0.1 \cdot  \sin^2 (\phi)\right) \cdot sin(\theta)$	&  $\theta_0 \in [-\pi,\pi]$, $\phi_0 \in [-\pi/2,\pi/2]$ & 400 \\
%van der Pol oscillator & $\dot{x} = 10 \cdot  \left(y - \frac{1}{3} \cdot (x^3-x) \right)$	, $ \dot{y} = -\frac{1}{10} \cdot x$		& $x,y \in [0,1]$  & 400 \\ \midrule
%\end{tabularx}
%\end{table}
%\begin{table}
%\begin{tabularx}{\columnwidth}{X X r r r} 
%\multicolumn{5}{c}{Program Synthesis}\\ 
%Problem	& Input & Output	& Training Cases & training cases \\\midrule
%Number IO & integer in [-100,100], float in [-100.0, 100.0]	&	printed float & 25 & 1000 \\
%Wallis PI & integer in [1, 200] & float &	150 & 50 \\
%Vector Average & vector of float of length [1,50] with each float in [-1000.0, 1000.0]	& float &	100	&	1000 \\ 
%\bottomrule
%\end{tabularx}
%\end{table}



\section{Results}\label{s:results}
The boxplots in Figure~\ref{fig:boxplot_reg} show the test set MSE for each method on each problem. In the final subplot, we summarize the mean rankings of the methods on each trial of each problem to give a general comparison of performance. In general we find that the $\epsilon$-lexicase methods produce models with the best generalization performance across the tested problems. Random selection and Lasso tend to perform the worst on these problems. It is interesting to note the performance of Lasso on the Tower problem, which is better than on other datasets; ep-lex-sd and ep-lex-d are the only GP variants to significantly outperform it. For every problem, a variant of $\epsilon$-lexicase selection performs the best, and the three variants of it tend to perform similarly. In accordance with previous results~\citep{la_cava_epsilon-lexicase_2016}, lexicase selection performs worse than tournament selection for these continuous valued problems. In contrast with previous findings~\citep{schmidt_age-fitness_2011}, dc tends to outperform afp, although both methods perform better than tournament selection. 

The $\epsilon$-lexicase methods show a marked advantage in converging on a low training error in fewer generations compared to all other methods, as evidenced in Figure~\ref{fig:train}. Note Figure~\ref{fig:train} reports the normalized MSE values on the training set for the best individual in the population each generation. Again we observe very little difference between the $\epsilon$-lexicase variants. 

We analyze the statistical significance of the test MSE results in Tables~\ref{tbl:wilcox} and~\ref{tbl:hsd}. Table~\ref{tbl:wilcox} shows pair-wise Wilcoxon ranksum tests for each method in comparison to ep-lex-sd. There are significant differences in performance for all problems between ep-lex-sd and all non-$\epsilon$-lexicase methods, with the exception of the comparison to dc on the housing and tower datasets. Analysis of variance of the method rankings across all problems indicates significant differences ($p<$ 2e-16). A post-hoc statistical analysis shown in Table~\ref{tbl:hsd} indicates that this difference is due to significant differences in rankings across all problems for ep-lex-sd and ep-lex-d in pairwise comparison to all other non-$\epsilon$-lexicase methods. The three variants of $\epsilon$-lexicase do not differ significantly from each other according to this test.

Figure~\ref{fig:diversity} shows the semantic diversity of the populations for each generation using different selection methods. $\epsilon$-lexicase variants, dc, and lexicase selection all produce the highest population diversity, as expected due to their diversity maintenance design. Interestingly, they all produce more diverse semantics than random selection, suggesting that the preservation of {\it useful} diversity is an important feature of the observed performance improvements. Surprisingly, afp is found to produce low semantic diversity, despite its incorporation of age and random restarts each generation. Given that afp has no explicit semantic diversity mechanism, it's possible that age is not an adequate surrogate for behavioral diversity on these problems. 
  
One of the motivations for introducing an $\epsilon$ threshold into lexicase selection is to allow selection to make use of more cases in continuous domains when selecting parents. Figure~\ref{fig:case_depth} demonstrates that $\epsilon$-lexicase methods achieve this goal. As we noted at the beginning of \S\ref{s:eplex}, lexicase selection likely only uses one case per selection event in continuous domains, leading to poor performance. We observe this phenonemon in the median case depth measurements. Among the $\epsilon$-lexicase variants, ep-lex-sd uses the most cases in general, followed by ep-lex-s and ep-lex-d. Intuitively this result makes sense: $\epsilon$ is likely to be largest when computed across the population, and because ep-lex-sd uses the global $\epsilon$ (Eqn.~\ref{eq:ep}) and a local error threshold, it is likely to keep the most individuals at each case filtering. These results also suggest that $\epsilon$ shrinks substantially when calculated among the pool after each case (Eqn.~\ref{eq:epd}) in ep-lex-d. 


\begin{figure}
\centering
  \includegraphics[width=\textwidth]{figs/regression_boxplots.pdf}\\
  \caption{Boxplots of the mean squared error on the test set for 50 randomized trials of each algorithm on the regression benchmark datasets.}\label{fig:boxplot_reg}
\end{figure}

\begin{figure}
\centering
  \includegraphics[width=\textwidth]{figs/regression_training_error.pdf}\\
 \caption{Training error convergence for the best individual using different selection methods. The error bars represent 95\% confidence intervals over 50 trials.}
\label{fig:train}
\end{figure}

\begin{figure}
\centering
  \includegraphics[width=\textwidth]{figs/regression_novelty.pdf}\\
 \caption{Behavioral diversity (Eqn.~\ref{eq:diversity}) of the population using different selection methods. The error bars represent 95\% confidence intervals over 50 trials.}
\label{fig:diversity}
\end{figure}

\begin{figure}
\centering
  \includegraphics[width=\textwidth]{figs/median_case_depth.pdf}\\
 \caption{Median case depths of selection each generation for the lexicase selection variants on the regression problems.}\label{fig:case_depth}
\end{figure}

\label{tbl:tables===}

\input{tbl_wilcox}

\input{tbl_hsd}

\section{Discussion}\label{s:discuss}
The experimental results show that $\epsilon$-lexicase selection performs well on the symbolic regression problems studied compared to other methods. $\epsilon$-lexicase leads to quicker learning on the training set (Figure~\ref{fig:train}), better test set performance (Figure~\ref{fig:boxplot_reg}), and high semantic diversity throughout training (Figure~\ref{fig:diversity}). The variants of $\epsilon$-lexicase do not vary significantly from each other over all tested problems, which suggests that the foundations of the method are robust to different definitions of $\epsilon$ as long as they result in higher leverage of case information during selection. With this in mind, we suggest semi-dynamic $\epsilon$-lexicase (ep-lex-sd, Algorithm 3.2) as the default implementation since it performs similarly to dynamic $\epsilon$-lexicase (ep-lex-d), has a lower worst-case complexity (see \S\ref{s:eplex}), and appears to utilize the most case information according to Figure~\ref{fig:case_depth}. 
 
$\epsilon$-lexicase selection is a global pool, uniform random sequence, non-elitist version of lexicase selection~\citep{spector_assessment_2012}. ``Global pool" means that each selection event begins with the entire population. It is possible that smaller pools, defined geographically for example~\citep{spector_trivial_2006}, could improve performance on certain problems that respond well to relaxed selection pressure. ``Uniform random sequence" refers to the order of the cases, and unlike pool size, other orderings of training cases have yet to be reported in literature. One could consider biasing the ordering of cases in some ways that could select parents with certain desired properties. \cite{liskowski_comparison_2015} attempted to use derived objective clusters as cases in lexicase selection, but found that this actually decreased performance, possibly due to the small number of resultant objectives. Still, there may be a form of ordering or case reduction that improves lexicase selection's performance over random shuffling.   
 
The ordering of the training cases that produce a given parent also contains potentially useful information that could be used by the search operators in GP. \cite{helmuth_general_2015-1} observed that lexicase selection creates large numbers of distinct behavioral clusters in the population (an observation supported by Figure~\ref{fig:diversity}). In that regard, it may be advantageous, for instance, to perform crossover on individuals selected by differing orders of cases such that their offspring are more likely to inherit subprograms with unique partial solutions to a given task. On the other hand, one could argue for pairing individuals based on similar selection cases, to promote niching and minimize the destructive nature of subtree crossover.    

Based on the observations in \S\ref{s:prob}, when the training set is much larger than the population size, some cases are likely to go unused. In these scenarios it may be advantageous to reduce program evaluations by lazily evaluating programs on cases as they appear in selection events. Indeed, Eqn.~\ref{eq:prob_case} could be used as a guide for determining when a lazy evaluation strategy would lead to significant computational savings.

\section{Conclusions}\label{s:conclusion}
In this paper we present a probabilistic and multi-objective analysis of lexicase selection and $\epsilon$-lexicase selection. We develop the expected probabilities of selection under lexicase selection variants, and show the impact of population size and training set size on probabilities of selection. For the first time, the connection between lexicase selection and multi-objective optimization is analyzed, showing that individuals selected by lexicase selection occupy the boundaries or near boundaries of the Pareto front in the high-dimensional space spanned by the population errors. 

In addition, we experimentally validate $\epsilon$-lexicase selection, including two new variants, on a set of real-world and synthetic symbolic regression problems. The results suggest that $\epsilon$-lexicase selection strongly improves the ability of GP to find accurate models. Further analysis of these runs show that lexicase variants maintain exceptionally high diversity during evolution, and that $\epsilon$-lexicase variants consider more cases per selection event than standard lexicase selection. The results validate our motivation for creating this variant of lexicase for continuous domains, and suggest the adoption of lexicase selection and variants of it in similar domains.  

\section{Acknowledgments}
This work was supported by the Warren Center for Network and Data Science at the University of Pennsylvania, as well as NIH grants P30-ES013508, AI116794 and LM009012. This material is based upon work supported by the National Science Foundation under Grants No. 1617087, 1129139 and 1331283. Any opinions, findings, and conclusions or recommendations expressed in this publication are those of the authors and do not necessarily reflect the views of the National Science Foundation.


\bibliographystyle{apalike}
\bibliography{epsilon_lexicase}


\end{document}
